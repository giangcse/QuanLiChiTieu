# -*- coding: utf-8 -*-

import logging
import re
import pandas as pd
from datetime import datetime
from telegram import Update, ForceReply
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes

# Th∆∞ vi·ªán cho Machine Learning
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
import numpy as np

# Th∆∞ vi·ªán ƒë·ªÉ l√†m vi·ªác v·ªõi file .env
import os
from dotenv import load_dotenv

# Th∆∞ vi·ªán ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì
import matplotlib.pyplot as plt
import io

# --- C·∫§U H√åNH ---
# T·∫£i c√°c bi·∫øn m√¥i tr∆∞·ªùng t·ª´ file .env v√†o h·ªá th·ªëng
load_dotenv()

# L·∫•y token t·ª´ bi·∫øn m√¥i tr∆∞·ªùng ƒë√£ t·∫£i
TOKEN = os.getenv('TELEGRAM_API_TOKEN')
DATA_FILE = 'thu_chi_data.csv'

# B·∫≠t logging ƒë·ªÉ theo d√µi v√† g·ª° l·ªói
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO
)
logger = logging.getLogger(__name__)

# --- B·ªò PH·∫¨N M√ÅY H·ªåC ---
expense_model = None
income_model = None

def train_models():
    """Hu·∫•n luy·ªán ƒë·ªìng th·ªùi c·∫£ hai m√¥ h√¨nh ph√¢n lo·∫°i cho Thu v√† Chi."""
    global expense_model, income_model
    logger.info("B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán c√°c m√¥ h√¨nh v·ªõi d·ªØ li·ªáu m·ªü r·ªông...")
    
    # --- D·ªØ li·ªáu hu·∫•n luy·ªán cho CHI TI√äU (M·ªü r·ªông) ---
    expense_data = [
        # ƒÇn u·ªëng
        ("c∆°m s∆∞·ªùn tr∆∞a", "ƒÇn u·ªëng"), ("mua ly tr√† s·ªØa", "ƒÇn u·ªëng"), ("c√† ph√™ v·ªõi b·∫°n", "ƒÇn u·ªëng"),
        ("ƒÉn t·ªëi nh√† h√†ng", "ƒÇn u·ªëng"), ("b√∫n ch·∫£", "ƒÇn u·ªëng"), ("ph·ªü b√≤", "ƒÇn u·ªëng"),
        ("ƒëi ƒÉn l·∫©u", "ƒÇn u·ªëng"), ("mua ƒë·ªì ƒÉn v·∫∑t", "ƒÇn u·ªëng"), ("thanh to√°n ahamove", "ƒÇn u·ªëng"),
        ("tr√† ƒë√°", "ƒÇn u·ªëng"), ("ƒëi ch·ª£ mua th·ª©c ƒÉn", "ƒÇn u·ªëng"),
        # ƒêi l·∫°i
        ("ƒë·ªï xƒÉng xe m√°y", "ƒêi l·∫°i"), ("v√© xe bus th√°ng", "ƒêi l·∫°i"), ("ti·ªÅn grab ƒëi l√†m", "ƒêi l·∫°i"),
        ("g·ª≠i xe", "ƒêi l·∫°i"), ("ti·ªÅn v√© m√°y bay", "ƒêi l·∫°i"), ("ph√≠ c·∫ßu ƒë∆∞·ªùng", "ƒêi l·∫°i"),
        ("b·∫£o d∆∞·ª°ng xe", "ƒêi l·∫°i"), ("r·ª≠a xe", "ƒêi l·∫°i"),
        # Mua s·∫Øm
        ("mua √°o s∆° mi", "Mua s·∫Øm"), ("ƒë·∫∑t h√†ng shopee", "Mua s·∫Øm"), ("mua m·ªôt ƒë√¥i gi√†y m·ªõi", "Mua s·∫Øm"),
        ("mua s√°ch", "Mua s·∫Øm"), ("mua ƒë·ªì gia d·ª•ng", "Mua s·∫Øm"), ("mua qu√† sinh nh·∫≠t", "Mua s·∫Øm"),
        ("thanh to√°n tiki", "Mua s·∫Øm"), ("mua s·∫Øm lazada", "Mua s·∫Øm"),
        # H√≥a ƒë∆°n
        ("thanh to√°n ti·ªÅn ƒëi·ªán", "H√≥a ƒë∆°n"), ("ƒë√≥ng ti·ªÅn net FPT", "H√≥a ƒë∆°n"), ("ti·ªÅn nh√† th√°ng 8", "H√≥a ƒë∆°n"),
        ("ti·ªÅn m·∫°ng viettel", "H√≥a ƒë∆°n"), ("ph√≠ chung c∆∞", "H√≥a ƒë∆°n"), ("truy·ªÅn h√¨nh c√°p", "H√≥a ƒë∆°n"),
        ("n·∫°p ti·ªÅn ƒëi·ªán tho·∫°i", "H√≥a ƒë∆°n"),
        # Gi·∫£i tr√≠
        ("v√© xem phim cgv", "Gi·∫£i tr√≠"), ("mua v√© concert", "Gi·∫£i tr√≠"), ("ƒëi bar", "Gi·∫£i tr√≠"),
        ("ƒëƒÉng k√Ω gym", "Gi·∫£i tr√≠"), ("mua game tr√™n steam", "Gi·∫£i tr√≠"),
        # S·ª©c kh·ªèe
        ("mua thu·ªëc c·∫£m", "S·ª©c kh·ªèe"), ("ti·ªÅn kh√°m rƒÉng", "S·ª©c kh·ªèe"), ("mua vitamin", "S·ª©c kh·ªèe"),
        ("kh√°m b·ªánh", "S·ª©c kh·ªèe"),
        # Gi√°o d·ª•c
        ("h·ªçc ph√≠ kh√≥a h·ªçc online", "Gi√°o d·ª•c"), ("mua t√†i li·ªáu h·ªçc", "Gi√°o d·ª•c"), ("ƒë√≥ng ti·ªÅn h·ªçc", "Gi√°o d·ª•c"),
    ]
    expense_descriptions = [item[0] for item in expense_data]
    expense_categories = [item[1] for item in expense_data]
    expense_model = Pipeline([('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])
    expense_model.fit(expense_descriptions, expense_categories)
    logger.info("Hu·∫•n luy·ªán m√¥ h√¨nh CHI TI√äU th√†nh c√¥ng!")

    # --- D·ªØ li·ªáu hu·∫•n luy·ªán cho THU NH·∫¨P (M·ªü r·ªông) ---
    income_data = [
        # L∆∞∆°ng
        ("l∆∞∆°ng th√°ng 8", "L∆∞∆°ng"), ("nh·∫≠n l∆∞∆°ng c√¥ng ty", "L∆∞∆°ng"), ("l∆∞∆°ng th√°ng 7", "L∆∞∆°ng"),
        ("l∆∞∆°ng part-time", "L∆∞∆°ng"), ("nh·∫≠n l∆∞∆°ng", "L∆∞∆°ng"), ("ting ting l∆∞∆°ng v·ªÅ", "L∆∞∆°ng"),
        # Th∆∞·ªüng
        ("th∆∞·ªüng d·ª± √°n", "Th∆∞·ªüng"), ("ƒë∆∞·ª£c s·∫øp th∆∞·ªüng", "Th∆∞·ªüng"), ("th∆∞·ªüng l·ªÖ", "Th∆∞·ªüng"),
        ("th∆∞·ªüng cu·ªëi nƒÉm", "Th∆∞·ªüng"), ("bonus", "Th∆∞·ªüng"), ("nh·∫≠n ti·ªÅn th∆∞·ªüng", "Th∆∞·ªüng"),
        # Thu nh·∫≠p ph·ª•
        ("ti·ªÅn cho thu√™ xe", "Thu nh·∫≠p ph·ª•"), ("cho thu√™ nh√†", "Thu nh·∫≠p ph·ª•"), ("b√°n ƒë·ªì c≈© online", "Thu nh·∫≠p ph·ª•"),
        ("ti·ªÅn d·∫°y th√™m", "Thu nh·∫≠p ph·ª•"), ("l√†m freelancer", "Thu nh·∫≠p ph·ª•"), ("ti·ªÅn cho thu√™ ph√≤ng", "Thu nh·∫≠p ph·ª•"),
        ("b√°n h√†ng online", "Thu nh·∫≠p ph·ª•"),
        # ƒê·∫ßu t∆∞
        ("l√£i ng√¢n h√†ng", "ƒê·∫ßu t∆∞"), ("l·ª£i nhu·∫≠n ch·ª©ng kho√°n", "ƒê·∫ßu t∆∞"), ("ti·ªÅn c·ªï t·ª©c", "ƒê·∫ßu t∆∞"),
        ("l√£i ti·∫øt ki·ªám", "ƒê·∫ßu t∆∞"),
        # Ngu·ªìn kh√°c
        ("ƒë∆∞·ª£c cho ti·ªÅn", "Kh√°c"), ("qu√† m·ª´ng c∆∞·ªõi", "Kh√°c"), ("nh·∫≠n ti·ªÅn ho√†n thu·∫ø", "Kh√°c"),
        ("b·ªë m·∫π cho", "Kh√°c"),
    ]
    income_descriptions = [item[0] for item in income_data]
    income_categories = [item[1] for item in income_data]
    income_model = Pipeline([('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])
    income_model.fit(income_descriptions, income_categories)
    logger.info("Hu·∫•n luy·ªán m√¥ h√¨nh THU NH·∫¨P th√†nh c√¥ng!")

def classify_transaction(description: str, transaction_type: str) -> str:
    """Ph√¢n lo·∫°i giao d·ªãch d·ª±a tr√™n lo·∫°i (thu/chi) b·∫±ng m√¥ h√¨nh ML."""
    if transaction_type == 'chi' and expense_model:
        return expense_model.predict([description])[0]
    elif transaction_type == 'thu' and income_model:
        return income_model.predict([description])[0]
    return "Kh√°c"

# --- C√ÅC H√ÄM X·ª¨ L√ù L·ªÜNH ---

async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """G·ª≠i tin nh·∫Øn ch√†o m·ª´ng khi ng∆∞·ªùi d√πng g√µ /start."""
    user = update.effective_user
    await update.message.reply_html(
        f"Xin ch√†o {user.mention_html()}!\n\n"
        f"T√¥i l√† –±–æ—Ç qu·∫£n l√Ω Thu - Chi c√° nh√¢n.\n\n"
        f"‚úçÔ∏è **ƒê·ªÉ ghi m·ªôt giao d·ªãch, ch·ªâ c·∫ßn g√µ s·ªë ti·ªÅn v√† n·ªôi dung.**\n"
        f"<b>V√≠ d·ª• chi ti√™u:</b> <code>50000 ƒÉn tr∆∞a</code>\n"
        f"<b>V√≠ d·ª• thu nh·∫≠p:</b> <code>thu 10000000 l∆∞∆°ng</code>\n\n"
        f"G√µ /help ƒë·ªÉ xem t·∫•t c·∫£ c√°c l·ªánh.",
        reply_markup=ForceReply(selective=True),
    )

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Hi·ªÉn th·ªã th√¥ng tin tr·ª£ gi√∫p v√† c√°c l·ªánh c√≥ s·∫µn."""
    await update.message.reply_text(
        "üí° **C√°c l·ªánh b·∫°n c√≥ th·ªÉ d√πng:**\n\n"
        "/start - B·∫Øt ƒë·∫ßu v√† xem h∆∞·ªõng d·∫´n\n"
        "/help - Xem l·∫°i tin nh·∫Øn n√†y\n"
        "/tuan - Th·ªëng k√™ Thu-Chi tu·∫ßn n√†y\n"
        "/thang - Th·ªëng k√™ Thu-Chi th√°ng n√†y\n"
        "/thongke - V·∫Ω bi·ªÉu ƒë·ªì chi ti√™u th√°ng n√†y"
    )

async def handle_transaction_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """X·ª≠ l√Ω tin nh·∫Øn giao d·ªãch m·ªôt c√°ch linh ho·∫°t."""
    text = update.message.text.lower()
    user_id = update.message.from_user.id
    numbers = re.findall(r'\d+', text)
    if not numbers:
        await update.message.reply_text('‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y s·ªë ti·ªÅn trong tin nh·∫Øn c·ªßa b·∫°n.')
        return
    amount = max([int(n) for n in numbers])
    description_full = text
    for num_str in numbers:
        description_full = re.sub(r'\b' + num_str + r'\b', '', description_full).strip()
    transaction_type = 'chi'
    icon = 'üí∏'
    if any(keyword in description_full.split() for keyword in ['thu', '+', 'nh·∫≠n', 'l∆∞∆°ng', 'th∆∞·ªüng', 'bonus', 'l√£i']):
        transaction_type = 'thu'
        icon = 'üí∞'
    keywords_to_remove = ['thu', 'chi', '+', '-']
    description_words = [word for word in description_full.split() if word not in keywords_to_remove]
    description = ' '.join(description_words).strip()
    if not description:
        await update.message.reply_text('‚ö†Ô∏è Giao d·ªãch c·ªßa b·∫°n c·∫ßn c√≥ n·ªôi dung m√¥ t·∫£.', parse_mode='HTML')
        return
    category = classify_transaction(description, transaction_type)
    date = datetime.now()
    save_transaction(user_id, date, amount, category, description, transaction_type)
    await update.message.reply_text(
        f'{icon} ƒê√£ ghi nh·∫≠n m·ªôt kho·∫£n <b>{transaction_type.upper()}</b>\n'
        f'<b>S·ªë ti·ªÅn:</b> {amount:,.0f} VNƒê\n'
        f'<b>N·ªôi dung:</b> {description}\n'
        f'<b>Danh m·ª•c:</b> {category}',
        parse_mode='HTML'
    )

async def weekly_stats_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Th·ªëng k√™ thu chi trong tu·∫ßn hi·ªán t·∫°i."""
    now = datetime.now()
    await generate_full_report(update, context, "week", f"Tu·∫ßn {now.isocalendar().week}, {now.year}")

async def monthly_stats_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Th·ªëng k√™ thu chi trong th√°ng hi·ªán t·∫°i."""
    now = datetime.now()
    await generate_full_report(update, context, "month", f"Th√°ng {now.month}/{now.year}")

async def thongke_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """T·∫°o v√† g·ª≠i bi·ªÉu ƒë·ªì th·ªëng k√™ chi ti√™u th√°ng hi·ªán t·∫°i."""
    user_id = update.message.from_user.id
    now = datetime.now()
    
    try:
        df = pd.read_csv(DATA_FILE)
        df['date'] = pd.to_datetime(df['date'])
    except FileNotFoundError:
        await update.message.reply_text('B·∫°n ch∆∞a c√≥ d·ªØ li·ªáu n√†o ƒë·ªÉ th·ªëng k√™.')
        return

    # L·ªçc d·ªØ li·ªáu chi ti√™u c·ªßa ng∆∞·ªùi d√πng trong th√°ng hi·ªán t·∫°i
    expense_df = df[
        (df['user_id'] == user_id) &
        (df['type'] == 'chi') &
        (df['date'].dt.month == now.month) &
        (df['date'].dt.year == now.year)
    ]

    if expense_df.empty:
        await update.message.reply_text('B·∫°n kh√¥ng c√≥ chi ti√™u n√†o trong th√°ng n√†y ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì.')
        return

    # Nh√≥m theo danh m·ª•c v√† t√≠nh t·ªïng
    category_stats = expense_df.groupby('category')['amount'].sum()

    # V·∫Ω bi·ªÉu ƒë·ªì
    plt.style.use('seaborn-v0_8-pastel')
    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(aspect="equal"))

    labels = category_stats.index
    sizes = category_stats.values

    wedges, texts, autotexts = ax.pie(sizes, autopct='%1.1f%%', startangle=90, textprops=dict(color="w"))
    
    ax.legend(wedges, labels,
              title="Danh m·ª•c",
              loc="center left",
              bbox_to_anchor=(1, 0, 0.5, 1))
              
    plt.setp(autotexts, size=8, weight="bold")
    ax.set_title(f"Bi·ªÉu ƒë·ªì Chi ti√™u Th√°ng {now.month}/{now.year}")

    # L∆∞u bi·ªÉu ƒë·ªì v√†o m·ªôt buffer trong b·ªô nh·ªõ
    buf = io.BytesIO()
    plt.savefig(buf, format='png', bbox_inches='tight')
    plt.close(fig)
    buf.seek(0)

    # G·ª≠i ·∫£nh cho ng∆∞·ªùi d√πng
    await update.message.reply_photo(photo=buf, caption="ƒê√¢y l√† bi·ªÉu ƒë·ªì ph√¢n t√≠ch chi ti√™u th√°ng n√†y c·ªßa b·∫°n.")


# --- C√ÅC H√ÄM TI·ªÜN √çCH ---

def save_transaction(user_id, date, amount, category, description, transaction_type):
    """L∆∞u giao d·ªãch (thu ho·∫∑c chi) v√†o file CSV."""
    try:
        df = pd.read_csv(DATA_FILE)
    except FileNotFoundError:
        df = pd.DataFrame(columns=['user_id', 'date', 'type', 'amount', 'category', 'description'])
    new_row = pd.DataFrame([{'user_id': user_id, 'date': date.strftime('%Y-%m-%d %H:%M:%S'), 'type': transaction_type, 'amount': amount, 'category': category, 'description': description}])
    df = pd.concat([df, new_row], ignore_index=True)
    df.to_csv(DATA_FILE, index=False)

async def generate_full_report(update: Update, context: ContextTypes.DEFAULT_TYPE, period_type: str, period_name: str):
    """T·∫°o v√† g·ª≠i b√°o c√°o Thu-Chi t·ªïng h·ª£p cho m·ªôt kho·∫£ng th·ªùi gian."""
    user_id = update.message.from_user.id
    try:
        df = pd.read_csv(DATA_FILE)
        df['date'] = pd.to_datetime(df['date'])
    except FileNotFoundError:
        await update.message.reply_text('B·∫°n ch∆∞a c√≥ d·ªØ li·ªáu n√†o ƒë·ªÉ th·ªëng k√™.')
        return
    now = datetime.now()
    if period_type == "week":
        period_filter = (df['date'].dt.isocalendar().week == now.isocalendar().week) & (df['date'].dt.year == now.year)
    else:
        period_filter = (df['date'].dt.month == now.month) & (df['date'].dt.year == now.year)
    user_df = df[(df['user_id'] == user_id) & period_filter]
    if user_df.empty:
        await update.message.reply_text(f'B·∫°n kh√¥ng c√≥ giao d·ªãch n√†o trong {period_name.lower()}.')
        return
    income_df = user_df[user_df['type'] == 'thu']
    expense_df = user_df[user_df['type'] == 'chi']
    total_income = income_df['amount'].sum()
    total_expense = expense_df['amount'].sum()
    balance = total_income - total_expense
    response = f"üìä <b>B√°o c√°o t√†i ch√≠nh {period_name}</b>\n\n"
    response += f"üü¢ <b>T·ªïng Thu:</b> {total_income:,.0f} VNƒê\n"
    response += f"üî¥ <b>T·ªïng Chi:</b> {total_expense:,.0f} VNƒê\n"
    response += f"<b>‚éØ‚éØ‚éØ‚éØ‚éØ‚éØ‚éØ‚éØ‚éØ‚éØ‚éØ‚éØ‚éØ</b>\n"
    response += f"üìà <b>S·ªë d∆∞: {balance:,.0f} VNƒê</b>\n\n"
    if not income_df.empty:
        response += "<b>--- Chi ti·∫øt c√°c kho·∫£n THU ---</b>\n"
        income_stats = income_df.groupby('category')['amount'].sum().sort_values(ascending=False)
        for category, amount in income_stats.items():
            response += f"  - {category}: {amount:,.0f} VNƒê\n"
        response += "\n"
    if not expense_df.empty:
        response += "<b>--- Chi ti·∫øt c√°c kho·∫£n CHI ---</b>\n"
        expense_stats = expense_df.groupby('category')['amount'].sum().sort_values(ascending=False)
        for category, amount in expense_stats.items():
            response += f"  - {category}: {amount:,.0f} VNƒê\n"
    await update.message.reply_text(response, parse_mode='HTML')

# --- H√ÄM MAIN ƒê·ªÇ KH·ªûI ƒê·ªòNG BOT ---

def main() -> None:
    """Kh·ªüi ƒë·ªông bot v√† l·∫Øng nghe c√°c y√™u c·∫ßu."""
    if not TOKEN:
        logger.error("L·ªñI: Kh√¥ng t√¨m th·∫•y TELEGRAM_API_TOKEN trong file .env")
        return
    train_models()
    application = Application.builder().token(TOKEN).build()
    application.add_handler(CommandHandler("start", start_command))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("tuan", weekly_stats_command))
    application.add_handler(CommandHandler("thang", monthly_stats_command))
    application.add_handler(CommandHandler("thongke", thongke_command))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_transaction_message))
    print("Bot Qu·∫£n l√Ω Thu-Chi (phi√™n b·∫£n v·∫Ω bi·ªÉu ƒë·ªì) ƒëang ch·∫°y...")
    application.run_polling()
    print("Bot ƒë√£ d·ª´ng.")

if __name__ == '__main__':
    main()
